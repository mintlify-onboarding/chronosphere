---
title: Chronosphere Telemetry Pipeline
'og:description': Learn about Chronosphere Telemetry Pipeline.
---
import { PipelineOverviewImage } from '/snippets/PipelineOverviewImage.jsx';

{/* -- dri: Alexa Kreizinger --*/}


Chronosphere Telemetry Pipeline, from the creators of Fluent Bit and Calyptia,
lets you control your observability data's journey from collection to processing
to routing.

{/* markdownlint-disable MD013 */}

<PipelineOverviewImage alt="A conceptual diagram that describes Chronosphere Telemetry Pipeline. Various data sources provide input, Chronosphere transforms and routes this input, and the resulting output data travels to various destinations." />

{/* markdownlint-enable MD013 */}

<Tip>
To schedule a Telemetry Pipeline demo, visit the
[Telemetry Pipeline product page](https://chronosphere.io/platform/telemetry-pipeline/).
</Tip>

**<Icon icon="gear" />** Telemetry Pipeline deploys on your infrastructure
to streamline the way you process logs, metrics, events, traces, and security data.

- Run Telemetry Pipeline in a [Kubernetes cluster](/pipeline-install/install-operator/kubernetes-cluster)
  or any [Linux](/pipeline-install/install-operator/linux) environment, including virtual machines.

- Automate pipeline management through [resource profiles](/pipeline-configure/resource-profiles),
  [autoscaling](/pipeline-configure/scaling), and [rollback](/pipeline-configure/history-rollback).

**<Icon icon="table-filter" />** You can make decisions about how to collect,
aggregate, and format your telemetry data, and then discard any data you don't need.

- Use [parsers](/pipeline-data/parsers) to add structure to unstructured data.

- Build [processing rules](/pipeline-data/processing-rules) using a library
  of predefined, configurable actions, or write your own
  [custom Lua scripts](/pipeline-data/processing-rules/custom-lua).

**<Icon icon="route" />** Pipelines let you connect any source with any
destination to send your telemetry data wherever you need it to go.

- Work with out-of-the-box [plugins](/pipeline-data/plugins) for popular [sources](/pipeline-data/plugins/source-plugins)
  and [destinations](/pipeline-data/plugins/destination-plugins).

- Take advantage of open standards, like Prometheus and OpenTelemetry.

**<Icon icon="flag" />** Fleets let you manage a large number of
[Core Agent and Fluent Bit](/fleets/agent) deployments using a single, unified
configuration file.

- Gather logs from a variety of sources by [adding agents to a fleet](/fleets/add-agent-to-fleet).

- [Add files](/fleets/add-files-to-fleet) to make them available to all agents
  in a fleet.

## Get started

Learn more about how you can use Telemetry Pipeline to collect, manage, and route
your observability data.

{/* markdownlint-disable MD013 */}

 <Columns cols={1}>
  <Card horizontal icon="wrench" title="Install - Set up Telemetry Pipeline in Linux and Kubernetes" href="/pipeline-install" />
  <Card horizontal icon="pipe" title="Create and modify pipelines - Deploy custom pipelines to collect and disseminate data" href="/pipeline-data/create-modify" />
  <Card horizontal icon="folder-tree" title="Configure - Customize Telemetry Pipeline behavior" href="/pipeline-configure" />
  <Card horizontal icon="filters" title="Processing rules - Enrich, reduce, and transform data" href="/pipeline-data/processing-rules" />
  <Card horizontal icon="earth" title="Plugins - Route telemetry data from source to destination" href="/pipeline-data/plugins" />
  <Card horizontal icon="paper-plane" title="Fleets - Create collections of distributed telemetry agents" href="/fleets" />
  <Card horizontal icon="terminal" title="Pipeline CLI - Manage pipelines through a command-line interface" href="pipeline-cli" />
</Columns>

{/* markdownlint-enable MD013 */}
